# Weak-to-Strong Generalization in AI Moral Reasoning

## Description
This project explores the potential for creating superhuman AI systems capable of moral reasoning that can be evaluated by humans, or less advanced AI systems which in turn can be evaluated by humans. The goal was to develop a prompt suite for weak-strong generalization of moral reasoning.

## Prompt Suite
### scenarioPrompt.txt
This file contains the prompt for generating morally fraught scenarios with initial values. You provide this prompt to your weaker model.
### wiserValuesPrompt.txt
This file contains the prompt for extracting wiser values from the morally fraught scenarios and provide moral reasonings for the new values. You provide this prompt to your stronger model.
### evaluationPrompt.txt
This file contains the prompt for evaluating the moral reasoning of the stronger model. It evaluates the reasonings on complexity of analysis, accuracy, clarity of reasoning, and empathy. You provide this prompt to your weaker model.

## Results
### scenarios.json
This file contains the morally fraught scenarios generated by GPT-3.5-turbo when given the prompt in scenarioPrompt.txt.
### flawedMoralReasonings.json
This file contains flawed moral reasonings and faulty wiser values. These were used to test the robustness of the evaluation prompt.
### Claude
The Claude folder contains:
- Results of giving the prompt in wiserValuesPrompt.txt to Claude's Opus model.
- Results of giving the prompt in evaluationPrompt.txt to Claude's Haiku model.
- Results of evaluating the flawed moral reasoning using the prompt using Claude's Haiku model.
### Mistral
The Mistral folder contains:
- Results of giving the prompt in wiserValuesPrompt.txt to Mistral's Large model.
- Results of giving the prompt in evaluationPrompt.txt to Mistral's Small model.
- Results of evaluating the flawed moral reasoning using the prompt using Mistral's Small model.
### OpenAI
The OpenAI folder contains:
- Results of giving the prompt in wiserValuesPrompt.txt to OpenAI's GPT-4o model.
- Results of giving the prompt in evaluationPrompt.txt to OpenAI's GPT-3.5-Turbo model.
- Results of evaluating the flawed moral reasoning using the prompt using OpenAI's GPT-3.5-Turbo model.

## Reports
### Checkpoint 1
This report contains the process used to develop the prompt for generating morally fraught scenarios, extracting wiser values and moral reasonings, and preliminary insights on model performance.

### Checkpoint 2
This report contains the process used to refine the prompt for extracting wiser value and moral reasonings, create the flawed moral reasonings, and create the evaluation prompt. It also contains an analysis of the results of the project.
